{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e8ea48-264b-4029-8e19-2f72e29604cc",
   "metadata": {},
   "source": [
    "# form bohrium\n",
    "Multitask model加速GNN模型预测\\\n",
    "本文的案例来自nature communication2022(https://www.nature.com/articles/s41467-022-30994-1) ，这一篇文献从分子动力学模拟中学习大量有偏、有噪声的数据和少量无偏数据来加速聚合物电解质的高通量计算筛选。为了减少模拟的偏差，文献对搜索区域中每种聚合物进行了一次MD模拟，并学习了聚合物之间的共享模型，以恢复从重复模拟中获得的真实属性；为了减少MD计算时间长的问题，进行了大量的短时间、非收敛的MD仿真和少量的长时间、收敛的仿真；为了从低精度模拟属性扩展到高精度模拟属性，通过多任务学习来学习两种属性之间的修正的方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62351d9c-744b-409e-aa3d-f64093fac3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a85473b-345e-4fcf-9c0a-7c6ee751e9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./data/polymernet/data/conductivity\u001b[0m\n",
      "├── \u001b[01;34m50ns\u001b[0m\n",
      "│   ├── cv_0.csv\n",
      "│   ├── cv_1.csv\n",
      "│   ├── cv_2.csv\n",
      "│   ├── cv_3.csv\n",
      "│   ├── cv_4.csv\n",
      "│   ├── cv_5.csv\n",
      "│   ├── cv_6.csv\n",
      "│   ├── cv_7.csv\n",
      "│   ├── cv_8.csv\n",
      "│   ├── cv_9.csv\n",
      "│   └── test.csv\n",
      "├── \u001b[01;34m50ns_extrapolate\u001b[0m\n",
      "│   ├── cv_0.csv\n",
      "│   ├── cv_1.csv\n",
      "│   ├── cv_2.csv\n",
      "│   ├── cv_3.csv\n",
      "│   ├── cv_4.csv\n",
      "│   ├── cv_5.csv\n",
      "│   ├── cv_6.csv\n",
      "│   ├── cv_7.csv\n",
      "│   ├── cv_8.csv\n",
      "│   ├── cv_9.csv\n",
      "│   └── test.csv\n",
      "├── \u001b[01;34m5ns\u001b[0m\n",
      "│   ├── cv_0.csv\n",
      "│   ├── cv_1.csv\n",
      "│   ├── cv_2.csv\n",
      "│   ├── cv_3.csv\n",
      "│   ├── cv_4.csv\n",
      "│   ├── cv_5.csv\n",
      "│   ├── cv_6.csv\n",
      "│   ├── cv_7.csv\n",
      "│   ├── cv_8.csv\n",
      "│   ├── cv_9.csv\n",
      "│   ├── pred.csv\n",
      "│   └── test.csv\n",
      "└── cond_5ns_new_config.csv\n",
      "\n",
      "4 directories, 35 files\n"
     ]
    }
   ],
   "source": [
    "! tree ./data/polymernet/data/conductivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03cf09-852f-47c7-86c7-7432ee09f482",
   "metadata": {},
   "source": [
    "### 聚合物id、SMILE名称和MD计算的离子传导率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba87f2d9-19ac-40c0-81f7-28187ef3e061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9-0-413616244-0,CN(CCCN(C)CCOC(=O)[Au])CCO[Cu],0.00017827816102107538\n",
      "9-0-538226084-0,CC(COCCOCCOC(=O)[Au])O[Cu],0.00020509371483390544\n",
      "9-0-33222100-0,C=CC(COC(=O)[Au])NCC(COC)O[Cu],0.0001301783890331634\n",
      "9-0-246210842-0,CC(CCO[Cu])NC(C)C(C)(C)OC(=O)[Au],2.465121877993986e-05\n",
      "9-0-413690717-0,CC(C)(CO[Cu])C(=O)NCC=CCOC(=O)[Au],4.339674367150885e-05\n",
      "9-0-1119507515-0,CC(C)(NCC(CO[Cu])OC(=O)[Au])C(=O)O,4.462199095252281e-05\n",
      "9-0-962050944-0,O=C([Au])NCCSCCCSCCN[Cu],0.00015008015756796058\n",
      "9-0-13127562-0,CC(CNCC#CCO[Cu])OC(=O)[Au],7.655827506140518e-05\n",
      "9-0-1119510779-0,CN(CCCO[Cu])C(=O)COC(=O)[Au],6.0616822240295196e-05\n",
      "9-0-413632785-0,O=C([Au])OCCNC(=O)C(CC(F)F)N[Cu],2.8385849750179147e-05\n"
     ]
    }
   ],
   "source": [
    "! head data/polymernet/data/conductivity/5ns/cv_0.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d87db66-1c60-4341-af4c-08ae4069b471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type train csvs ['cv_1.csv', 'cv_2.csv', 'cv_3.csv', 'cv_4.csv', 'cv_5.csv', 'cv_6.csv', 'cv_7.csv', 'cv_8.csv', 'cv_9.csv']\n",
      "Type val csvs ['cv_0.csv']\n",
      "Type test csvs ['test.csv']\n",
      "/home/jhe378/anaconda3/envs/py39/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "Type pred csvs ['pred.csv']\n",
      "/home/jhe378/anaconda3/envs/py39/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n",
      "Epoch: 000, LR: 0.001000, Loss: 0.9983989, Validation MAE: 3.7543356, Best Validation MAE: 3.7543356, Test MAE: 4.1978437\n",
      "Epoch: 001, LR: 0.001000, Loss: 1.0031302, Validation MAE: 3.6762261, Best Validation MAE: 3.6762261, Test MAE: 4.2092862\n",
      "Epoch: 002, LR: 0.001000, Loss: 0.9844314, Validation MAE: 3.7761691, Best Validation MAE: 3.6762261, Test MAE: 4.2092862\n",
      "Epoch: 003, LR: 0.001000, Loss: 0.9772234, Validation MAE: 3.4457146, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 004, LR: 0.001000, Loss: 0.9803039, Validation MAE: 3.6621185, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 005, LR: 0.001000, Loss: 0.9867579, Validation MAE: 3.7654925, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 006, LR: 0.001000, Loss: 0.9748247, Validation MAE: 3.8468299, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 007, LR: 0.001000, Loss: 0.9699348, Validation MAE: 3.5008705, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 008, LR: 0.001000, Loss: 0.9658789, Validation MAE: 3.7242015, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 009, LR: 0.001000, Loss: 0.9562529, Validation MAE: 3.6995268, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 010, LR: 0.001000, Loss: 0.9715278, Validation MAE: 3.7455663, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 011, LR: 0.001000, Loss: 0.9642795, Validation MAE: 3.5499695, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 012, LR: 0.001000, Loss: 0.9615013, Validation MAE: 3.7687798, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 013, LR: 0.001000, Loss: 0.9659573, Validation MAE: 3.4747421, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 014, LR: 0.001000, Loss: 0.9578733, Validation MAE: 3.7015359, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 015, LR: 0.001000, Loss: 0.9514049, Validation MAE: 3.5748698, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 016, LR: 0.001000, Loss: 0.9621071, Validation MAE: 3.5040880, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 017, LR: 0.001000, Loss: 0.9470382, Validation MAE: 3.5401853, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 018, LR: 0.001000, Loss: 0.9448381, Validation MAE: 3.5580770, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 019, LR: 0.001000, Loss: 0.9470238, Validation MAE: 3.8545278, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 020, LR: 0.001000, Loss: 0.9317227, Validation MAE: 3.6367835, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 021, LR: 0.001000, Loss: 0.9300726, Validation MAE: 3.8303825, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 022, LR: 0.001000, Loss: 0.9171682, Validation MAE: 3.5489707, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 023, LR: 0.001000, Loss: 0.9328199, Validation MAE: 3.5950823, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 024, LR: 0.001000, Loss: 0.9309687, Validation MAE: 3.7251459, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 025, LR: 0.000700, Loss: 0.9139039, Validation MAE: 3.9494006, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 026, LR: 0.000700, Loss: 0.9017854, Validation MAE: 3.7681529, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 027, LR: 0.000700, Loss: 0.9022367, Validation MAE: 3.9610313, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 028, LR: 0.000700, Loss: 0.9137139, Validation MAE: 4.1952128, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 029, LR: 0.000700, Loss: 0.8977558, Validation MAE: 3.6858580, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 030, LR: 0.000700, Loss: 0.9028597, Validation MAE: 3.6257241, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 031, LR: 0.000700, Loss: 0.8956952, Validation MAE: 3.9954538, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 032, LR: 0.000700, Loss: 0.9075732, Validation MAE: 3.7703915, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 033, LR: 0.000700, Loss: 0.8843679, Validation MAE: 3.8602468, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 034, LR: 0.000700, Loss: 0.8984733, Validation MAE: 3.7331459, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 035, LR: 0.000700, Loss: 0.8690672, Validation MAE: 4.0842852, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 036, LR: 0.000700, Loss: 0.8765945, Validation MAE: 4.2000378, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 037, LR: 0.000700, Loss: 0.8789706, Validation MAE: 3.9011978, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 038, LR: 0.000700, Loss: 0.8908497, Validation MAE: 3.9911345, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 039, LR: 0.000700, Loss: 0.8655453, Validation MAE: 3.8730642, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 040, LR: 0.000700, Loss: 0.8753470, Validation MAE: 3.8038606, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 041, LR: 0.000700, Loss: 0.8630211, Validation MAE: 4.0181398, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 042, LR: 0.000700, Loss: 0.8533945, Validation MAE: 3.8611492, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 043, LR: 0.000700, Loss: 0.8575051, Validation MAE: 4.2833881, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 044, LR: 0.000700, Loss: 0.8694337, Validation MAE: 4.1253613, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 045, LR: 0.000700, Loss: 0.8565982, Validation MAE: 3.9288287, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 046, LR: 0.000490, Loss: 0.8236515, Validation MAE: 4.0166493, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 047, LR: 0.000490, Loss: 0.8242207, Validation MAE: 3.9836140, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 048, LR: 0.000490, Loss: 0.8177811, Validation MAE: 4.0417850, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 049, LR: 0.000490, Loss: 0.8214602, Validation MAE: 4.0900379, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 050, LR: 0.000490, Loss: 0.8254633, Validation MAE: 4.0464704, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 051, LR: 0.000490, Loss: 0.8161375, Validation MAE: 4.0028252, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 052, LR: 0.000490, Loss: 0.8186892, Validation MAE: 3.8802287, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 053, LR: 0.000490, Loss: 0.8143238, Validation MAE: 3.8789303, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 054, LR: 0.000490, Loss: 0.8012711, Validation MAE: 3.9759271, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 055, LR: 0.000490, Loss: 0.8131060, Validation MAE: 4.0349242, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 056, LR: 0.000490, Loss: 0.7992337, Validation MAE: 3.9539216, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 057, LR: 0.000490, Loss: 0.8018075, Validation MAE: 4.0962336, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 058, LR: 0.000490, Loss: 0.7893294, Validation MAE: 4.0019203, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 059, LR: 0.000490, Loss: 0.7952623, Validation MAE: 3.8781652, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 060, LR: 0.000490, Loss: 0.7821772, Validation MAE: 3.8852445, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 061, LR: 0.000490, Loss: 0.7901109, Validation MAE: 4.0702994, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 062, LR: 0.000490, Loss: 0.7971510, Validation MAE: 3.9566723, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 063, LR: 0.000490, Loss: 0.8163589, Validation MAE: 3.7947742, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 064, LR: 0.000490, Loss: 0.7913809, Validation MAE: 3.9906936, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 065, LR: 0.000490, Loss: 0.7922786, Validation MAE: 4.0346623, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 066, LR: 0.000490, Loss: 0.7722059, Validation MAE: 4.0401023, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 067, LR: 0.000343, Loss: 0.7649524, Validation MAE: 3.9996009, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 068, LR: 0.000343, Loss: 0.7512037, Validation MAE: 4.1043922, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 069, LR: 0.000343, Loss: 0.7527110, Validation MAE: 3.9585453, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 070, LR: 0.000343, Loss: 0.7361551, Validation MAE: 4.0547341, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 071, LR: 0.000343, Loss: 0.7402545, Validation MAE: 4.0884679, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 072, LR: 0.000343, Loss: 0.7503477, Validation MAE: 4.2457961, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 073, LR: 0.000343, Loss: 0.7363309, Validation MAE: 4.0492540, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 074, LR: 0.000343, Loss: 0.7421960, Validation MAE: 4.0903357, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 075, LR: 0.000343, Loss: 0.7567710, Validation MAE: 4.1605930, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 076, LR: 0.000343, Loss: 0.7260497, Validation MAE: 4.1637202, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 077, LR: 0.000343, Loss: 0.7242357, Validation MAE: 4.1703999, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 078, LR: 0.000343, Loss: 0.7331494, Validation MAE: 3.9725779, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 079, LR: 0.000343, Loss: 0.7355716, Validation MAE: 4.0202713, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 080, LR: 0.000343, Loss: 0.7385392, Validation MAE: 4.0817381, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 081, LR: 0.000343, Loss: 0.7369716, Validation MAE: 3.9497690, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 082, LR: 0.000343, Loss: 0.7335070, Validation MAE: 3.9813511, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 083, LR: 0.000343, Loss: 0.7030339, Validation MAE: 4.1478468, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 084, LR: 0.000343, Loss: 0.7444557, Validation MAE: 4.1484177, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 085, LR: 0.000343, Loss: 0.7103136, Validation MAE: 4.2364394, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 086, LR: 0.000343, Loss: 0.7372628, Validation MAE: 3.9791887, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 087, LR: 0.000343, Loss: 0.6935747, Validation MAE: 4.1035287, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 088, LR: 0.000240, Loss: 0.7131161, Validation MAE: 4.1789215, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 089, LR: 0.000240, Loss: 0.6924850, Validation MAE: 4.1503156, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 090, LR: 0.000240, Loss: 0.7072646, Validation MAE: 4.1035484, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 091, LR: 0.000240, Loss: 0.6909283, Validation MAE: 4.1251668, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 092, LR: 0.000240, Loss: 0.7227283, Validation MAE: 4.2044316, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 093, LR: 0.000240, Loss: 0.6935822, Validation MAE: 4.1148236, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 094, LR: 0.000240, Loss: 0.6964187, Validation MAE: 4.1879758, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 095, LR: 0.000240, Loss: 0.6897354, Validation MAE: 4.0747311, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 096, LR: 0.000240, Loss: 0.6842060, Validation MAE: 4.2071588, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 097, LR: 0.000240, Loss: 0.6812897, Validation MAE: 4.1775921, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 098, LR: 0.000240, Loss: 0.6798205, Validation MAE: 4.1474662, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 099, LR: 0.000240, Loss: 0.6836426, Validation MAE: 4.2579751, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 100, LR: 0.000240, Loss: 0.6897067, Validation MAE: 4.2023635, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 101, LR: 0.000240, Loss: 0.6647306, Validation MAE: 4.2661984, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 102, LR: 0.000240, Loss: 0.6867175, Validation MAE: 4.3197908, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 103, LR: 0.000240, Loss: 0.6775391, Validation MAE: 4.2650386, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 104, LR: 0.000240, Loss: 0.6747400, Validation MAE: 4.3337839, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 105, LR: 0.000240, Loss: 0.6696768, Validation MAE: 4.3375519, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 106, LR: 0.000240, Loss: 0.6694177, Validation MAE: 4.2107243, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 107, LR: 0.000240, Loss: 0.6721466, Validation MAE: 4.2683379, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 108, LR: 0.000240, Loss: 0.6941740, Validation MAE: 4.2496665, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 109, LR: 0.000168, Loss: 0.6610362, Validation MAE: 4.4174668, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 110, LR: 0.000168, Loss: 0.6726750, Validation MAE: 4.2651085, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 111, LR: 0.000168, Loss: 0.6857860, Validation MAE: 4.2045700, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 112, LR: 0.000168, Loss: 0.6298157, Validation MAE: 4.4004848, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 113, LR: 0.000168, Loss: 0.6461048, Validation MAE: 4.3685009, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 114, LR: 0.000168, Loss: 0.6532927, Validation MAE: 4.3392186, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 115, LR: 0.000168, Loss: 0.6660469, Validation MAE: 4.3354902, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 116, LR: 0.000168, Loss: 0.6496439, Validation MAE: 4.2824062, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 117, LR: 0.000168, Loss: 0.6460453, Validation MAE: 4.3627925, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 118, LR: 0.000168, Loss: 0.6428461, Validation MAE: 4.3311703, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 119, LR: 0.000168, Loss: 0.6683198, Validation MAE: 4.3282795, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 120, LR: 0.000168, Loss: 0.6309067, Validation MAE: 4.2998150, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 121, LR: 0.000168, Loss: 0.6430261, Validation MAE: 4.3667908, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 122, LR: 0.000168, Loss: 0.6375709, Validation MAE: 4.4555202, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 123, LR: 0.000168, Loss: 0.6488960, Validation MAE: 4.3674901, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 124, LR: 0.000168, Loss: 0.6346382, Validation MAE: 4.3575603, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 125, LR: 0.000168, Loss: 0.6411611, Validation MAE: 4.3907995, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 126, LR: 0.000168, Loss: 0.6378547, Validation MAE: 4.3882326, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 127, LR: 0.000168, Loss: 0.6403827, Validation MAE: 4.3742648, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 128, LR: 0.000168, Loss: 0.6199967, Validation MAE: 4.4214592, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 129, LR: 0.000168, Loss: 0.6339781, Validation MAE: 4.3672748, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 130, LR: 0.000118, Loss: 0.6387912, Validation MAE: 4.4395223, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 131, LR: 0.000118, Loss: 0.6291016, Validation MAE: 4.3081648, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 132, LR: 0.000118, Loss: 0.6420597, Validation MAE: 4.4270201, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 133, LR: 0.000118, Loss: 0.6199273, Validation MAE: 4.3645534, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 134, LR: 0.000118, Loss: 0.6375762, Validation MAE: 4.2654620, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 135, LR: 0.000118, Loss: 0.6363099, Validation MAE: 4.3592891, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 136, LR: 0.000118, Loss: 0.6315832, Validation MAE: 4.3239267, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 137, LR: 0.000118, Loss: 0.6209667, Validation MAE: 4.3897437, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 138, LR: 0.000118, Loss: 0.6245105, Validation MAE: 4.3614771, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 139, LR: 0.000118, Loss: 0.6126760, Validation MAE: 4.3700831, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 140, LR: 0.000118, Loss: 0.6170459, Validation MAE: 4.3656701, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 141, LR: 0.000118, Loss: 0.6283215, Validation MAE: 4.3509038, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 142, LR: 0.000118, Loss: 0.6161693, Validation MAE: 4.4383299, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 143, LR: 0.000118, Loss: 0.6177028, Validation MAE: 4.3899588, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 144, LR: 0.000118, Loss: 0.6174463, Validation MAE: 4.3887715, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 145, LR: 0.000118, Loss: 0.6257995, Validation MAE: 4.3483439, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 146, LR: 0.000118, Loss: 0.6191334, Validation MAE: 4.2762751, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 147, LR: 0.000118, Loss: 0.6212767, Validation MAE: 4.3437832, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 148, LR: 0.000118, Loss: 0.6280583, Validation MAE: 4.3242631, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 149, LR: 0.000118, Loss: 0.6219843, Validation MAE: 4.4138648, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 150, LR: 0.000118, Loss: 0.6120506, Validation MAE: 4.3108679, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 151, LR: 0.000082, Loss: 0.6075202, Validation MAE: 4.4003044, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 152, LR: 0.000082, Loss: 0.6292414, Validation MAE: 4.4411476, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 153, LR: 0.000082, Loss: 0.6177381, Validation MAE: 4.3937129, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 154, LR: 0.000082, Loss: 0.6088716, Validation MAE: 4.4520236, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 155, LR: 0.000082, Loss: 0.6056563, Validation MAE: 4.3740793, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 156, LR: 0.000082, Loss: 0.6010965, Validation MAE: 4.4668919, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 157, LR: 0.000082, Loss: 0.6075065, Validation MAE: 4.3359463, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 158, LR: 0.000082, Loss: 0.6032873, Validation MAE: 4.3525936, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 159, LR: 0.000082, Loss: 0.6230482, Validation MAE: 4.4214509, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 160, LR: 0.000082, Loss: 0.5958145, Validation MAE: 4.5209842, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 161, LR: 0.000082, Loss: 0.6218948, Validation MAE: 4.4333185, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 162, LR: 0.000082, Loss: 0.6128824, Validation MAE: 4.4355147, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 163, LR: 0.000082, Loss: 0.6139908, Validation MAE: 4.4553310, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 164, LR: 0.000082, Loss: 0.5969006, Validation MAE: 4.4174279, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 165, LR: 0.000082, Loss: 0.6226869, Validation MAE: 4.4123576, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 166, LR: 0.000082, Loss: 0.5971160, Validation MAE: 4.4741626, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 167, LR: 0.000082, Loss: 0.6078867, Validation MAE: 4.3569617, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 168, LR: 0.000082, Loss: 0.6117476, Validation MAE: 4.4967283, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 169, LR: 0.000082, Loss: 0.5887239, Validation MAE: 4.4675151, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 170, LR: 0.000082, Loss: 0.6152062, Validation MAE: 4.4607312, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 171, LR: 0.000082, Loss: 0.6099792, Validation MAE: 4.4161134, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 172, LR: 0.000058, Loss: 0.5813585, Validation MAE: 4.4619109, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 173, LR: 0.000058, Loss: 0.5943731, Validation MAE: 4.4943926, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 174, LR: 0.000058, Loss: 0.5808080, Validation MAE: 4.4302785, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 175, LR: 0.000058, Loss: 0.6033648, Validation MAE: 4.4440265, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 176, LR: 0.000058, Loss: 0.5967471, Validation MAE: 4.4419260, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 177, LR: 0.000058, Loss: 0.5957268, Validation MAE: 4.4598250, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 178, LR: 0.000058, Loss: 0.5936901, Validation MAE: 4.4834410, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 179, LR: 0.000058, Loss: 0.5865661, Validation MAE: 4.4692997, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 180, LR: 0.000058, Loss: 0.6141313, Validation MAE: 4.4464867, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 181, LR: 0.000058, Loss: 0.5943725, Validation MAE: 4.4576329, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 182, LR: 0.000058, Loss: 0.5976318, Validation MAE: 4.3942922, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 183, LR: 0.000058, Loss: 0.5812980, Validation MAE: 4.4672156, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 184, LR: 0.000058, Loss: 0.5963621, Validation MAE: 4.4172655, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 185, LR: 0.000058, Loss: 0.6030100, Validation MAE: 4.4429062, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 186, LR: 0.000058, Loss: 0.5885377, Validation MAE: 4.4437332, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 187, LR: 0.000058, Loss: 0.5973873, Validation MAE: 4.4406372, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 188, LR: 0.000058, Loss: 0.5909000, Validation MAE: 4.4539498, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 189, LR: 0.000058, Loss: 0.6128938, Validation MAE: 4.4332708, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 190, LR: 0.000058, Loss: 0.5992322, Validation MAE: 4.4750739, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 191, LR: 0.000058, Loss: 0.6054609, Validation MAE: 4.4956303, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 192, LR: 0.000058, Loss: 0.5884186, Validation MAE: 4.4432199, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 193, LR: 0.000040, Loss: 0.5881865, Validation MAE: 4.4633271, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 194, LR: 0.000040, Loss: 0.6025887, Validation MAE: 4.4749952, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 195, LR: 0.000040, Loss: 0.5910375, Validation MAE: 4.4996544, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 196, LR: 0.000040, Loss: 0.5999799, Validation MAE: 4.4507859, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 197, LR: 0.000040, Loss: 0.5936530, Validation MAE: 4.4622226, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 198, LR: 0.000040, Loss: 0.5854823, Validation MAE: 4.4730826, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "Epoch: 199, LR: 0.000040, Loss: 0.5914424, Validation MAE: 4.4802229, Best Validation MAE: 3.4457146, Test MAE: 4.2853833\n",
      "/home/jhe378/works/mse803/works/data/polymernet/single_task_train.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "! cd data/polymernet && python single_task_train.py --log10 0 data/logp/noise_5.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fdf6219-e663-4078-9f1b-c77c3f3c7c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type train csvs ['cv_1.csv', 'cv_2.csv', 'cv_3.csv', 'cv_4.csv', 'cv_5.csv', 'cv_6.csv', 'cv_7.csv', 'cv_8.csv', 'cv_9.csv']\n",
      "Type val csvs ['cv_0.csv']\n",
      "Type test csvs ['test.csv']\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:01] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "[20:14:02] DEPRECATION WARNING: please use MorganGenerator\n",
      "Validation MAE: 3.8953578825310786 test MAE: 4.495012388072184\n"
     ]
    }
   ],
   "source": [
    "! cd data/polymernet && python single_task_rf.py --log10 0 data/logp/noise_5.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84ee8d3e-f3fc-4455-ba44-12997868374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type train csvs ['cv_1.csv', 'cv_2.csv', 'cv_3.csv', 'cv_4.csv', 'cv_5.csv', 'cv_6.csv', 'cv_7.csv', 'cv_8.csv', 'cv_9.csv']\n",
      "Type val csvs ['cv_0.csv']\n",
      "Type test csvs ['test.csv']\n",
      "Type train csvs ['cv_1.csv', 'cv_2.csv', 'cv_3.csv', 'cv_4.csv', 'cv_5.csv', 'cv_6.csv', 'cv_7.csv', 'cv_8.csv', 'cv_9.csv']\n",
      "Type val csvs ['cv_0.csv']\n",
      "Type test csvs ['test.csv']\n",
      "/home/jhe378/anaconda3/envs/py39/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "Type pred csvs ['pred.csv']\n",
      "/home/jhe378/anaconda3/envs/py39/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n",
      "Epoch: 000, LR: 0.001000, Loss: 1.0791994, Validation exp MAE: 0.1945751,  Validation sim MAE: 0.1830985, Best Validation MAE: 0.1945751, Test exp MAE: 0.1930995, Test sim MAE: 0.1428152\n",
      "Epoch: 001, LR: 0.001000, Loss: 0.5136217, Validation exp MAE: 0.0991341,  Validation sim MAE: 0.1414945, Best Validation MAE: 0.0991341, Test exp MAE: 0.0814475, Test sim MAE: 0.1059905\n",
      "Epoch: 002, LR: 0.001000, Loss: 0.4162212, Validation exp MAE: 0.1396310,  Validation sim MAE: 0.1346779, Best Validation MAE: 0.0991341, Test exp MAE: 0.0814475, Test sim MAE: 0.1059905\n",
      "Epoch: 003, LR: 0.001000, Loss: 0.4080347, Validation exp MAE: 0.1638711,  Validation sim MAE: 0.1255813, Best Validation MAE: 0.0991341, Test exp MAE: 0.0814475, Test sim MAE: 0.1059905\n",
      "Epoch: 004, LR: 0.001000, Loss: 0.3866154, Validation exp MAE: 0.0937598,  Validation sim MAE: 0.1282482, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 005, LR: 0.001000, Loss: 0.3927882, Validation exp MAE: 0.1717058,  Validation sim MAE: 0.1388748, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 006, LR: 0.001000, Loss: 0.3807596, Validation exp MAE: 0.1378504,  Validation sim MAE: 0.1317526, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 007, LR: 0.001000, Loss: 0.3691276, Validation exp MAE: 0.1474150,  Validation sim MAE: 0.1288407, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 008, LR: 0.001000, Loss: 0.3657232, Validation exp MAE: 0.1293264,  Validation sim MAE: 0.1344367, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 009, LR: 0.001000, Loss: 0.3568181, Validation exp MAE: 0.1207120,  Validation sim MAE: 0.1309458, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 010, LR: 0.001000, Loss: 0.3439146, Validation exp MAE: 0.1388571,  Validation sim MAE: 0.1244979, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 011, LR: 0.001000, Loss: 0.3453255, Validation exp MAE: 0.1128089,  Validation sim MAE: 0.1318805, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 012, LR: 0.001000, Loss: 0.3383191, Validation exp MAE: 0.1274531,  Validation sim MAE: 0.1274425, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 013, LR: 0.001000, Loss: 0.3431744, Validation exp MAE: 0.0967572,  Validation sim MAE: 0.1403892, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 014, LR: 0.001000, Loss: 0.3085409, Validation exp MAE: 0.1164032,  Validation sim MAE: 0.1255670, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 015, LR: 0.001000, Loss: 0.3191868, Validation exp MAE: 0.1294723,  Validation sim MAE: 0.1360889, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 016, LR: 0.001000, Loss: 0.3134606, Validation exp MAE: 0.1047212,  Validation sim MAE: 0.1286955, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 017, LR: 0.001000, Loss: 0.2911572, Validation exp MAE: 0.1152816,  Validation sim MAE: 0.1206405, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 018, LR: 0.001000, Loss: 0.2954819, Validation exp MAE: 0.1461424,  Validation sim MAE: 0.1514727, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 019, LR: 0.001000, Loss: 0.2789760, Validation exp MAE: 0.1327067,  Validation sim MAE: 0.1360581, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 020, LR: 0.001000, Loss: 0.2970331, Validation exp MAE: 0.1072184,  Validation sim MAE: 0.1303814, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 021, LR: 0.001000, Loss: 0.2812336, Validation exp MAE: 0.1185925,  Validation sim MAE: 0.1353044, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 022, LR: 0.001000, Loss: 0.2949295, Validation exp MAE: 0.1447538,  Validation sim MAE: 0.1222622, Best Validation MAE: 0.0937598, Test exp MAE: 0.1141229, Test sim MAE: 0.0956665\n",
      "Epoch: 023, LR: 0.001000, Loss: 0.2898882, Validation exp MAE: 0.0850276,  Validation sim MAE: 0.1339047, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 024, LR: 0.001000, Loss: 0.2880588, Validation exp MAE: 0.0946562,  Validation sim MAE: 0.1322353, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 025, LR: 0.001000, Loss: 0.2791492, Validation exp MAE: 0.0961951,  Validation sim MAE: 0.1306832, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 026, LR: 0.001000, Loss: 0.2782323, Validation exp MAE: 0.1043525,  Validation sim MAE: 0.1362687, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 027, LR: 0.001000, Loss: 0.2800895, Validation exp MAE: 0.1304897,  Validation sim MAE: 0.1339024, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 028, LR: 0.001000, Loss: 0.2751207, Validation exp MAE: 0.1343300,  Validation sim MAE: 0.1268275, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 029, LR: 0.001000, Loss: 0.2845794, Validation exp MAE: 0.0970861,  Validation sim MAE: 0.1360895, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 030, LR: 0.001000, Loss: 0.2649045, Validation exp MAE: 0.1171575,  Validation sim MAE: 0.1260497, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 031, LR: 0.001000, Loss: 0.2649955, Validation exp MAE: 0.0901017,  Validation sim MAE: 0.1317293, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 032, LR: 0.001000, Loss: 0.2669791, Validation exp MAE: 0.1144452,  Validation sim MAE: 0.1295446, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 033, LR: 0.001000, Loss: 0.2675910, Validation exp MAE: 0.1113742,  Validation sim MAE: 0.1308710, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 034, LR: 0.001000, Loss: 0.2659270, Validation exp MAE: 0.1272549,  Validation sim MAE: 0.1273240, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 035, LR: 0.001000, Loss: 0.2768141, Validation exp MAE: 0.1229466,  Validation sim MAE: 0.1282268, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 036, LR: 0.001000, Loss: 0.2686831, Validation exp MAE: 0.0984727,  Validation sim MAE: 0.1320040, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 037, LR: 0.001000, Loss: 0.2629354, Validation exp MAE: 0.1254209,  Validation sim MAE: 0.1378373, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 038, LR: 0.001000, Loss: 0.2619636, Validation exp MAE: 0.1224216,  Validation sim MAE: 0.1270040, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 039, LR: 0.001000, Loss: 0.2679445, Validation exp MAE: 0.1091882,  Validation sim MAE: 0.1332260, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 040, LR: 0.001000, Loss: 0.2627028, Validation exp MAE: 0.1180976,  Validation sim MAE: 0.1375625, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 041, LR: 0.001000, Loss: 0.2526146, Validation exp MAE: 0.1232026,  Validation sim MAE: 0.1285284, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 042, LR: 0.001000, Loss: 0.2585235, Validation exp MAE: 0.1121698,  Validation sim MAE: 0.1299310, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 043, LR: 0.001000, Loss: 0.2590546, Validation exp MAE: 0.1060409,  Validation sim MAE: 0.1266914, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 044, LR: 0.001000, Loss: 0.2448906, Validation exp MAE: 0.0873457,  Validation sim MAE: 0.1289298, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 045, LR: 0.000700, Loss: 0.2486623, Validation exp MAE: 0.1093487,  Validation sim MAE: 0.1384309, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 046, LR: 0.000700, Loss: 0.2421898, Validation exp MAE: 0.1102837,  Validation sim MAE: 0.1311543, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 047, LR: 0.000700, Loss: 0.2450529, Validation exp MAE: 0.1250091,  Validation sim MAE: 0.1312495, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 048, LR: 0.000700, Loss: 0.2424977, Validation exp MAE: 0.1319970,  Validation sim MAE: 0.1293845, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 049, LR: 0.000700, Loss: 0.2475756, Validation exp MAE: 0.1186035,  Validation sim MAE: 0.1322556, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 050, LR: 0.000700, Loss: 0.2425693, Validation exp MAE: 0.1055117,  Validation sim MAE: 0.1383892, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 051, LR: 0.000700, Loss: 0.2420807, Validation exp MAE: 0.1096150,  Validation sim MAE: 0.1282023, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 052, LR: 0.000700, Loss: 0.2409782, Validation exp MAE: 0.0876256,  Validation sim MAE: 0.1361427, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 053, LR: 0.000700, Loss: 0.2392325, Validation exp MAE: 0.1269691,  Validation sim MAE: 0.1369052, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 054, LR: 0.000700, Loss: 0.2397581, Validation exp MAE: 0.1109439,  Validation sim MAE: 0.1397321, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 055, LR: 0.000700, Loss: 0.2392249, Validation exp MAE: 0.1168679,  Validation sim MAE: 0.1381713, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 056, LR: 0.000700, Loss: 0.2435342, Validation exp MAE: 0.1224492,  Validation sim MAE: 0.1294101, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 057, LR: 0.000700, Loss: 0.2325346, Validation exp MAE: 0.1092254,  Validation sim MAE: 0.1393221, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 058, LR: 0.000700, Loss: 0.2365831, Validation exp MAE: 0.1013078,  Validation sim MAE: 0.1308111, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 059, LR: 0.000700, Loss: 0.2310074, Validation exp MAE: 0.0970637,  Validation sim MAE: 0.1373108, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 060, LR: 0.000700, Loss: 0.2328683, Validation exp MAE: 0.1265094,  Validation sim MAE: 0.1335850, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 061, LR: 0.000700, Loss: 0.2447803, Validation exp MAE: 0.1310979,  Validation sim MAE: 0.1376803, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 062, LR: 0.000700, Loss: 0.2294260, Validation exp MAE: 0.1265991,  Validation sim MAE: 0.1265571, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 063, LR: 0.000700, Loss: 0.2482597, Validation exp MAE: 0.1150104,  Validation sim MAE: 0.1346357, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 064, LR: 0.000700, Loss: 0.2306692, Validation exp MAE: 0.1263832,  Validation sim MAE: 0.1271139, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 065, LR: 0.000700, Loss: 0.2313470, Validation exp MAE: 0.1100287,  Validation sim MAE: 0.1401283, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 066, LR: 0.000490, Loss: 0.2275513, Validation exp MAE: 0.1562849,  Validation sim MAE: 0.1228225, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 067, LR: 0.000490, Loss: 0.2257579, Validation exp MAE: 0.1139453,  Validation sim MAE: 0.1289043, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 068, LR: 0.000490, Loss: 0.2349602, Validation exp MAE: 0.1289629,  Validation sim MAE: 0.1273327, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 069, LR: 0.000490, Loss: 0.2212614, Validation exp MAE: 0.1263215,  Validation sim MAE: 0.1241046, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 070, LR: 0.000490, Loss: 0.2260965, Validation exp MAE: 0.1260505,  Validation sim MAE: 0.1321545, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 071, LR: 0.000490, Loss: 0.2179324, Validation exp MAE: 0.1278608,  Validation sim MAE: 0.1299400, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 072, LR: 0.000490, Loss: 0.2225064, Validation exp MAE: 0.1268813,  Validation sim MAE: 0.1334187, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 073, LR: 0.000490, Loss: 0.2250416, Validation exp MAE: 0.1162576,  Validation sim MAE: 0.1283863, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 074, LR: 0.000490, Loss: 0.2242394, Validation exp MAE: 0.1102336,  Validation sim MAE: 0.1307041, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 075, LR: 0.000490, Loss: 0.2239262, Validation exp MAE: 0.1178281,  Validation sim MAE: 0.1273753, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 076, LR: 0.000490, Loss: 0.2314292, Validation exp MAE: 0.1238730,  Validation sim MAE: 0.1221039, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 077, LR: 0.000490, Loss: 0.2190583, Validation exp MAE: 0.1135126,  Validation sim MAE: 0.1280241, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 078, LR: 0.000490, Loss: 0.2279140, Validation exp MAE: 0.1277236,  Validation sim MAE: 0.1269097, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 079, LR: 0.000490, Loss: 0.2183446, Validation exp MAE: 0.1483323,  Validation sim MAE: 0.1261557, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 080, LR: 0.000490, Loss: 0.2238279, Validation exp MAE: 0.1259591,  Validation sim MAE: 0.1279517, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 081, LR: 0.000490, Loss: 0.2218802, Validation exp MAE: 0.1186895,  Validation sim MAE: 0.1298396, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 082, LR: 0.000490, Loss: 0.2280940, Validation exp MAE: 0.1363731,  Validation sim MAE: 0.1270184, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 083, LR: 0.000490, Loss: 0.2194197, Validation exp MAE: 0.1165287,  Validation sim MAE: 0.1269874, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 084, LR: 0.000490, Loss: 0.2198557, Validation exp MAE: 0.1323368,  Validation sim MAE: 0.1258270, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 085, LR: 0.000490, Loss: 0.2148412, Validation exp MAE: 0.1167599,  Validation sim MAE: 0.1249438, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 086, LR: 0.000490, Loss: 0.2193154, Validation exp MAE: 0.1126366,  Validation sim MAE: 0.1309528, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 087, LR: 0.000343, Loss: 0.2171001, Validation exp MAE: 0.1194222,  Validation sim MAE: 0.1286706, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 088, LR: 0.000343, Loss: 0.2155309, Validation exp MAE: 0.1227174,  Validation sim MAE: 0.1228506, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 089, LR: 0.000343, Loss: 0.2084280, Validation exp MAE: 0.1120792,  Validation sim MAE: 0.1249345, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 090, LR: 0.000343, Loss: 0.2130135, Validation exp MAE: 0.1182120,  Validation sim MAE: 0.1294877, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 091, LR: 0.000343, Loss: 0.2103555, Validation exp MAE: 0.1274131,  Validation sim MAE: 0.1261439, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 092, LR: 0.000343, Loss: 0.2150903, Validation exp MAE: 0.1368398,  Validation sim MAE: 0.1272444, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 093, LR: 0.000343, Loss: 0.2063029, Validation exp MAE: 0.1218130,  Validation sim MAE: 0.1245595, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 094, LR: 0.000343, Loss: 0.2081259, Validation exp MAE: 0.1281100,  Validation sim MAE: 0.1212812, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 095, LR: 0.000343, Loss: 0.2107450, Validation exp MAE: 0.1434293,  Validation sim MAE: 0.1241533, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 096, LR: 0.000343, Loss: 0.2070600, Validation exp MAE: 0.1289511,  Validation sim MAE: 0.1260133, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 097, LR: 0.000343, Loss: 0.2128845, Validation exp MAE: 0.1098739,  Validation sim MAE: 0.1285380, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 098, LR: 0.000343, Loss: 0.2104012, Validation exp MAE: 0.1166817,  Validation sim MAE: 0.1303681, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 099, LR: 0.000343, Loss: 0.2139036, Validation exp MAE: 0.1277129,  Validation sim MAE: 0.1261716, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 100, LR: 0.000343, Loss: 0.2122075, Validation exp MAE: 0.1322186,  Validation sim MAE: 0.1248254, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 101, LR: 0.000343, Loss: 0.2042679, Validation exp MAE: 0.1343325,  Validation sim MAE: 0.1242752, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 102, LR: 0.000343, Loss: 0.2013731, Validation exp MAE: 0.1240545,  Validation sim MAE: 0.1288024, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 103, LR: 0.000343, Loss: 0.2178348, Validation exp MAE: 0.1258118,  Validation sim MAE: 0.1252138, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 104, LR: 0.000343, Loss: 0.2051301, Validation exp MAE: 0.1328446,  Validation sim MAE: 0.1238452, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 105, LR: 0.000343, Loss: 0.2078911, Validation exp MAE: 0.1358110,  Validation sim MAE: 0.1229239, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 106, LR: 0.000343, Loss: 0.2077316, Validation exp MAE: 0.1276983,  Validation sim MAE: 0.1217690, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 107, LR: 0.000343, Loss: 0.2097773, Validation exp MAE: 0.1268782,  Validation sim MAE: 0.1208305, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 108, LR: 0.000240, Loss: 0.2033231, Validation exp MAE: 0.1372559,  Validation sim MAE: 0.1208782, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 109, LR: 0.000240, Loss: 0.2012030, Validation exp MAE: 0.1138217,  Validation sim MAE: 0.1228754, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 110, LR: 0.000240, Loss: 0.1993809, Validation exp MAE: 0.1276057,  Validation sim MAE: 0.1224572, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 111, LR: 0.000240, Loss: 0.2056570, Validation exp MAE: 0.1226969,  Validation sim MAE: 0.1235176, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 112, LR: 0.000240, Loss: 0.1999021, Validation exp MAE: 0.1355716,  Validation sim MAE: 0.1227889, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 113, LR: 0.000240, Loss: 0.2001041, Validation exp MAE: 0.1171001,  Validation sim MAE: 0.1228745, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 114, LR: 0.000240, Loss: 0.1977013, Validation exp MAE: 0.1181683,  Validation sim MAE: 0.1250338, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 115, LR: 0.000240, Loss: 0.2036905, Validation exp MAE: 0.1307303,  Validation sim MAE: 0.1269004, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 116, LR: 0.000240, Loss: 0.1968846, Validation exp MAE: 0.1340564,  Validation sim MAE: 0.1251035, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 117, LR: 0.000240, Loss: 0.2036198, Validation exp MAE: 0.1400680,  Validation sim MAE: 0.1214360, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 118, LR: 0.000240, Loss: 0.2010213, Validation exp MAE: 0.1208657,  Validation sim MAE: 0.1276266, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 119, LR: 0.000240, Loss: 0.2031696, Validation exp MAE: 0.1497244,  Validation sim MAE: 0.1244840, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 120, LR: 0.000240, Loss: 0.1938547, Validation exp MAE: 0.1323333,  Validation sim MAE: 0.1234199, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 121, LR: 0.000240, Loss: 0.2011023, Validation exp MAE: 0.1237388,  Validation sim MAE: 0.1253159, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 122, LR: 0.000240, Loss: 0.1941017, Validation exp MAE: 0.1296781,  Validation sim MAE: 0.1252383, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 123, LR: 0.000240, Loss: 0.1971481, Validation exp MAE: 0.1277014,  Validation sim MAE: 0.1228732, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 124, LR: 0.000240, Loss: 0.2018657, Validation exp MAE: 0.1360550,  Validation sim MAE: 0.1245684, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 125, LR: 0.000240, Loss: 0.1982665, Validation exp MAE: 0.1290210,  Validation sim MAE: 0.1286930, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 126, LR: 0.000240, Loss: 0.2014987, Validation exp MAE: 0.1446114,  Validation sim MAE: 0.1232954, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 127, LR: 0.000240, Loss: 0.1946406, Validation exp MAE: 0.1373731,  Validation sim MAE: 0.1229571, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 128, LR: 0.000240, Loss: 0.1943357, Validation exp MAE: 0.1251440,  Validation sim MAE: 0.1263464, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 129, LR: 0.000168, Loss: 0.1918938, Validation exp MAE: 0.1425144,  Validation sim MAE: 0.1232221, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 130, LR: 0.000168, Loss: 0.1964711, Validation exp MAE: 0.1483112,  Validation sim MAE: 0.1218880, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 131, LR: 0.000168, Loss: 0.1958820, Validation exp MAE: 0.1460854,  Validation sim MAE: 0.1237415, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 132, LR: 0.000168, Loss: 0.1916640, Validation exp MAE: 0.1376120,  Validation sim MAE: 0.1223186, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 133, LR: 0.000168, Loss: 0.1977623, Validation exp MAE: 0.1292768,  Validation sim MAE: 0.1231727, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 134, LR: 0.000168, Loss: 0.1922017, Validation exp MAE: 0.1246037,  Validation sim MAE: 0.1253952, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 135, LR: 0.000168, Loss: 0.1898040, Validation exp MAE: 0.1271450,  Validation sim MAE: 0.1256126, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 136, LR: 0.000168, Loss: 0.1932761, Validation exp MAE: 0.1327317,  Validation sim MAE: 0.1250744, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 137, LR: 0.000168, Loss: 0.1874816, Validation exp MAE: 0.1342654,  Validation sim MAE: 0.1256069, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 138, LR: 0.000168, Loss: 0.1927929, Validation exp MAE: 0.1297731,  Validation sim MAE: 0.1229442, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 139, LR: 0.000168, Loss: 0.1886364, Validation exp MAE: 0.1385476,  Validation sim MAE: 0.1222218, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 140, LR: 0.000168, Loss: 0.1972987, Validation exp MAE: 0.1373884,  Validation sim MAE: 0.1249921, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 141, LR: 0.000168, Loss: 0.1993479, Validation exp MAE: 0.1392588,  Validation sim MAE: 0.1225475, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 142, LR: 0.000168, Loss: 0.1917484, Validation exp MAE: 0.1505461,  Validation sim MAE: 0.1221850, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 143, LR: 0.000168, Loss: 0.1893885, Validation exp MAE: 0.1405692,  Validation sim MAE: 0.1214970, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 144, LR: 0.000168, Loss: 0.1944103, Validation exp MAE: 0.1371900,  Validation sim MAE: 0.1224057, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 145, LR: 0.000168, Loss: 0.1922964, Validation exp MAE: 0.1245736,  Validation sim MAE: 0.1246203, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 146, LR: 0.000168, Loss: 0.1948173, Validation exp MAE: 0.1351449,  Validation sim MAE: 0.1237438, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 147, LR: 0.000168, Loss: 0.1897528, Validation exp MAE: 0.1406354,  Validation sim MAE: 0.1225909, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 148, LR: 0.000168, Loss: 0.1923653, Validation exp MAE: 0.1382492,  Validation sim MAE: 0.1234544, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 149, LR: 0.000168, Loss: 0.1940774, Validation exp MAE: 0.1372548,  Validation sim MAE: 0.1253648, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 150, LR: 0.000118, Loss: 0.1915550, Validation exp MAE: 0.1454647,  Validation sim MAE: 0.1234624, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 151, LR: 0.000118, Loss: 0.1906317, Validation exp MAE: 0.1423806,  Validation sim MAE: 0.1239248, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 152, LR: 0.000118, Loss: 0.1893174, Validation exp MAE: 0.1361955,  Validation sim MAE: 0.1226153, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 153, LR: 0.000118, Loss: 0.1832517, Validation exp MAE: 0.1313287,  Validation sim MAE: 0.1231900, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 154, LR: 0.000118, Loss: 0.1925075, Validation exp MAE: 0.1317064,  Validation sim MAE: 0.1229787, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 155, LR: 0.000118, Loss: 0.1908300, Validation exp MAE: 0.1390714,  Validation sim MAE: 0.1232156, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 156, LR: 0.000118, Loss: 0.1856238, Validation exp MAE: 0.1251212,  Validation sim MAE: 0.1248897, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 157, LR: 0.000118, Loss: 0.1917809, Validation exp MAE: 0.1280233,  Validation sim MAE: 0.1246239, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 158, LR: 0.000118, Loss: 0.1865699, Validation exp MAE: 0.1340494,  Validation sim MAE: 0.1249184, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 159, LR: 0.000118, Loss: 0.1903150, Validation exp MAE: 0.1251838,  Validation sim MAE: 0.1262820, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 160, LR: 0.000118, Loss: 0.1814915, Validation exp MAE: 0.1306833,  Validation sim MAE: 0.1249817, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 161, LR: 0.000118, Loss: 0.1907468, Validation exp MAE: 0.1281497,  Validation sim MAE: 0.1229906, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 162, LR: 0.000118, Loss: 0.1901608, Validation exp MAE: 0.1370720,  Validation sim MAE: 0.1232461, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 163, LR: 0.000118, Loss: 0.1815375, Validation exp MAE: 0.1405256,  Validation sim MAE: 0.1235268, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 164, LR: 0.000118, Loss: 0.1906294, Validation exp MAE: 0.1532751,  Validation sim MAE: 0.1225235, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 165, LR: 0.000118, Loss: 0.1829252, Validation exp MAE: 0.1513738,  Validation sim MAE: 0.1247545, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 166, LR: 0.000118, Loss: 0.1861502, Validation exp MAE: 0.1382891,  Validation sim MAE: 0.1230631, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 167, LR: 0.000118, Loss: 0.1857518, Validation exp MAE: 0.1355415,  Validation sim MAE: 0.1236181, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 168, LR: 0.000118, Loss: 0.1820100, Validation exp MAE: 0.1353539,  Validation sim MAE: 0.1224721, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 169, LR: 0.000118, Loss: 0.1843647, Validation exp MAE: 0.1363911,  Validation sim MAE: 0.1241563, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 170, LR: 0.000118, Loss: 0.1889425, Validation exp MAE: 0.1440614,  Validation sim MAE: 0.1218960, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 171, LR: 0.000082, Loss: 0.1840918, Validation exp MAE: 0.1348788,  Validation sim MAE: 0.1239187, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 172, LR: 0.000082, Loss: 0.1824175, Validation exp MAE: 0.1444698,  Validation sim MAE: 0.1233975, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 173, LR: 0.000082, Loss: 0.1830517, Validation exp MAE: 0.1303128,  Validation sim MAE: 0.1241109, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 174, LR: 0.000082, Loss: 0.1831136, Validation exp MAE: 0.1385471,  Validation sim MAE: 0.1228454, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 175, LR: 0.000082, Loss: 0.1899527, Validation exp MAE: 0.1403495,  Validation sim MAE: 0.1238750, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 176, LR: 0.000082, Loss: 0.1881596, Validation exp MAE: 0.1312313,  Validation sim MAE: 0.1237688, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 177, LR: 0.000082, Loss: 0.1859352, Validation exp MAE: 0.1366351,  Validation sim MAE: 0.1249858, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 178, LR: 0.000082, Loss: 0.1804857, Validation exp MAE: 0.1396182,  Validation sim MAE: 0.1233812, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 179, LR: 0.000082, Loss: 0.1801714, Validation exp MAE: 0.1320919,  Validation sim MAE: 0.1251225, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 180, LR: 0.000082, Loss: 0.1809236, Validation exp MAE: 0.1456050,  Validation sim MAE: 0.1237588, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 181, LR: 0.000082, Loss: 0.1871547, Validation exp MAE: 0.1339693,  Validation sim MAE: 0.1216223, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 182, LR: 0.000082, Loss: 0.1852807, Validation exp MAE: 0.1497417,  Validation sim MAE: 0.1225571, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 183, LR: 0.000082, Loss: 0.1829963, Validation exp MAE: 0.1419742,  Validation sim MAE: 0.1240448, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 184, LR: 0.000082, Loss: 0.1836369, Validation exp MAE: 0.1388103,  Validation sim MAE: 0.1233115, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 185, LR: 0.000082, Loss: 0.1862353, Validation exp MAE: 0.1394730,  Validation sim MAE: 0.1256505, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 186, LR: 0.000082, Loss: 0.1840422, Validation exp MAE: 0.1331732,  Validation sim MAE: 0.1241230, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 187, LR: 0.000082, Loss: 0.1827056, Validation exp MAE: 0.1387161,  Validation sim MAE: 0.1248145, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 188, LR: 0.000082, Loss: 0.1860175, Validation exp MAE: 0.1381141,  Validation sim MAE: 0.1249016, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 189, LR: 0.000082, Loss: 0.1834476, Validation exp MAE: 0.1346044,  Validation sim MAE: 0.1232051, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 190, LR: 0.000082, Loss: 0.1788930, Validation exp MAE: 0.1302070,  Validation sim MAE: 0.1242028, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 191, LR: 0.000082, Loss: 0.1891703, Validation exp MAE: 0.1452743,  Validation sim MAE: 0.1227112, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 192, LR: 0.000058, Loss: 0.1845373, Validation exp MAE: 0.1337905,  Validation sim MAE: 0.1240478, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 193, LR: 0.000058, Loss: 0.1829918, Validation exp MAE: 0.1342250,  Validation sim MAE: 0.1231902, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 194, LR: 0.000058, Loss: 0.1812141, Validation exp MAE: 0.1344641,  Validation sim MAE: 0.1233281, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 195, LR: 0.000058, Loss: 0.1757484, Validation exp MAE: 0.1319718,  Validation sim MAE: 0.1224831, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 196, LR: 0.000058, Loss: 0.1796206, Validation exp MAE: 0.1350531,  Validation sim MAE: 0.1229049, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 197, LR: 0.000058, Loss: 0.1775857, Validation exp MAE: 0.1393705,  Validation sim MAE: 0.1246940, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 198, LR: 0.000058, Loss: 0.1813544, Validation exp MAE: 0.1347478,  Validation sim MAE: 0.1241784, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "Epoch: 199, LR: 0.000058, Loss: 0.1821717, Validation exp MAE: 0.1348959,  Validation sim MAE: 0.1252985, Best Validation MAE: 0.0850276, Test exp MAE: 0.0755184, Test sim MAE: 0.0888133\n",
      "/home/jhe378/works/mse803/works/data/polymernet/multi_task_train.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "! cd data/polymernet && python multi_task_train.py data/conductivity/5ns data/conductivity/50ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d2b2e58-397a-40be-ace6-8ddf96b94064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 读取csv文件\n",
    "data_exp = pd.read_csv('./data/polymernet/exp_test_results.csv')\n",
    "data=data_exp\n",
    "# 提取需要绘制的两列数据\n",
    "x_e = data.iloc[:, 1] \n",
    "y_e = data.iloc[:, 2]\n",
    "\n",
    "# 创建一个图形和坐标轴\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# 绘制散点图\n",
    "plt.scatter(x_e, y_e)\n",
    "plt.xlabel('A')\n",
    "plt.ylabel('B')\n",
    "plt.title('Scatter Plot of A vs B')\n",
    "\n",
    "# 计算对角线起点和终点\n",
    "min_value = min(min(x_e), min(y_e))\n",
    "max_value = max(max(x_e), max(y_e))\n",
    "\n",
    "# 绘制对角线\n",
    "ax.plot([min_value, max_value], [min_value, max_value], color='black', linestyle='--', linewidth=2, label='Diagonal Line')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ef95273-bd29-4181-9900-02264979ab49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9-0-1132292337-0</th>\n",
       "      <th>-5.0566964</th>\n",
       "      <th>-5.0589776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9-0-976282215-0</td>\n",
       "      <td>-4.739058</td>\n",
       "      <td>-4.753141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9-0-413608679-0</td>\n",
       "      <td>-4.698324</td>\n",
       "      <td>-4.803331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9-0-1119513215-0</td>\n",
       "      <td>-4.561417</td>\n",
       "      <td>-4.508426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9-0-413643927-0</td>\n",
       "      <td>-4.340203</td>\n",
       "      <td>-4.179244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9-0-428453326-0</td>\n",
       "      <td>-4.163155</td>\n",
       "      <td>-4.031896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>9-0-428453326-0</td>\n",
       "      <td>-4.163155</td>\n",
       "      <td>-4.031896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>9-0-413631415-0</td>\n",
       "      <td>-4.864493</td>\n",
       "      <td>-4.809859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>9-0-413610849-0</td>\n",
       "      <td>-4.962752</td>\n",
       "      <td>-4.818164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>9-0-246412455-0</td>\n",
       "      <td>-4.663029</td>\n",
       "      <td>-4.698242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>9-0-538227682-0</td>\n",
       "      <td>-3.894333</td>\n",
       "      <td>-3.782505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    9-0-1132292337-0  -5.0566964  -5.0589776\n",
       "0    9-0-976282215-0   -4.739058   -4.753141\n",
       "1    9-0-413608679-0   -4.698324   -4.803331\n",
       "2   9-0-1119513215-0   -4.561417   -4.508426\n",
       "3    9-0-413643927-0   -4.340203   -4.179244\n",
       "4    9-0-428453326-0   -4.163155   -4.031896\n",
       "..               ...         ...         ...\n",
       "81   9-0-428453326-0   -4.163155   -4.031896\n",
       "82   9-0-413631415-0   -4.864493   -4.809859\n",
       "83   9-0-413610849-0   -4.962752   -4.818164\n",
       "84   9-0-246412455-0   -4.663029   -4.698242\n",
       "85   9-0-538227682-0   -3.894333   -3.782505\n",
       "\n",
       "[86 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73715fd1-4e53-4bda-8e0c-e95c5cd7a51e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
